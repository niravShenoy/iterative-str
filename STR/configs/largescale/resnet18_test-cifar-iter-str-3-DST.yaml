# config to get 90.23% sparse ResNet50 on ImageNet. Modify this file to get other sparse models.
# Architecture
# arch: ResNet50

# ===== Dataset ===== #
# data: /mnt/data/
set: imagenet
resnet_type: res50
name: cifar10_resnet18_balanced_STR_Iter_LRR

# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 0.1
lr_policy: multistep_lr_imagenet
warmup_length: 10

# ===== Network training config ===== #
str_iterations: 2
epochs: 100
weight_decay: 0.0003 # Change this according to reported numbers in appendix
weight_decay_multiplier: 1.75
momentum: 0.9
batch_size: 256
label_smoothing: 0.1
lr_rewind: True
weights_sparsity_plot: True

# ===== Sparsity =========== #
er_sparse_init: 0.3
er_sparse_method: balanced
conv_type: STRConvER
bn_type: LearnedBatchNorm
init: kaiming_normal
mode: fan_in
nonlinearity: relu
sparse_function: sigmoid
sInit_value: -200 # Change this according to reported numbers in appendix

# ====== GraNet ============ #
dst_method: prune_and_grow
dst_init_prune_epoch: 150
dst_final_prune_epoch: 185
dst_prune_const: True
dst_const_prune_rate: 0.2
update_frequency: 5
is_reinitialze_grown_weights: True
is_update_pruned_weights: True
# final_density: 0.095  # Not needed as we are only regenerating


# ===== Hardware setup ===== #
workers: 4
